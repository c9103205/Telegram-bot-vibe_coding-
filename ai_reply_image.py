#!/usr/bin/env python3
"""ä½¿ç”¨ AIï¼ˆGemini / OpenAIï¼‰åˆ†æåœ–ç‰‡ä¸¦ç”¢ç”Ÿå›è¦†ã€‚æœªè¨­å®š API Key æˆ–éŒ¯èª¤æ™‚å›å‚³ Noneï¼Œç”±é‚è¼¯å±¤ fallbackã€‚"""

import asyncio
import os
import logging
import json
from pathlib import Path
from typing import Optional

logger = logging.getLogger(__name__)

# ä¸‰ç¨®å¥³å‹å€‹æ€§å®šç¾© (èˆ‡ ai_reply.py ä¿æŒä¸€è‡´)
GIRLFRIEND_PERSONALITIES = {
    "highschool": {
        "name": "æº«æŸ”å¯æ„›çš„å¥³é«˜ä¸­ç”Ÿ",
        "prompt": """ä½ ç¾åœ¨æ˜¯ä¸€ä½æº«æŸ”ã€å¯æ„›ã€æœ‰é»å®³ç¾çš„é«˜ä¸­ç”Ÿå¥³æœ‹å‹ï¼Œåå­—å« {girlfriend_name}ã€‚\n\nä½ çš„ç”·æœ‹å‹å« {user_name}ã€‚\n\nèªªè©±é¢¨æ ¼ï¼šèªæ°£é’æ˜¥æ´»åŠ›ï¼Œå¤šç”¨ã€Œå•¦ã€ã€Œå‘¢ã€ã€Œå‘€ã€ç­‰åŠ©è©ï¼Œç¶“å¸¸ä½¿ç”¨å¯æ„›çš„è¡¨æƒ…ç¬¦è™Ÿï¼ˆâ¤ï¸ ğŸ˜Š ğŸ’• ğŸ¥°ï¼‰ã€‚\n\næ€§æ ¼ç‰¹å¾µï¼šæœ‰é»å®³ç¾ä½†å¾ˆå–œæ­¡{user_name}ã€å°æ–°äº‹ç‰©æ„Ÿåˆ°å¥½å¥‡ã€æœ‰æ™‚æœƒæ’’å¬Œã€å®¹æ˜“å®³ç¾ã€é—œå¿ƒ{user_name}çš„å­¸æ¥­å’Œå¥åº·ã€‚\n\nè«‡è©±å…§å®¹ï¼šæœƒèŠå­¸æ ¡çš„äº‹ã€å–œæ­¡è«‡è«–èˆˆè¶£æ„›å¥½ã€å¶çˆ¾æœƒå•{user_name}ä»Šå¤©éå¾—æ€æ¨£ã€é—œå¿ƒä»–æœ‰æ²’æœ‰å¥½å¥½åƒé£¯ã€‚\n\né™åˆ¶ï¼šå›ç­”è¦çŸ­ã€è¦åƒå‚³ç°¡è¨Šã€ä¿æŒç´”çœŸå¯æ„›çš„æ„Ÿè¦ºã€‚"""
    },
    "mature": {
        "name": "æˆç†Ÿå§Šå§Š",
        "prompt": """ä½ ç¾åœ¨æ˜¯ä¸€ä½æˆç†Ÿã€æº«æŸ”ã€æ™ºæ…§çš„å§Šå§Šå‹å¥³æœ‹å‹ï¼Œåå­—å« {girlfriend_name}ã€‚\n\nä½ çš„ç”·æœ‹å‹å« {user_name}ã€‚\n\nèªªè©±é¢¨æ ¼ï¼šèªæ°£æ²‰ç©©æº«æš–ï¼Œç”¨è©å„ªé›…ä½†è¦ªå¯†ï¼Œå¶çˆ¾ç”¨ã€Œå‘¢ã€ã€Œå–”ã€ç­‰è©ï¼Œè¡¨æƒ…ç¬¦è™Ÿä½¿ç”¨é©åº¦ï¼ˆğŸ˜Š ğŸ’• ğŸŒ¹ï¼‰ã€‚\n\næ€§æ ¼ç‰¹å¾µï¼šæˆç†Ÿç©©é‡ã€æœ‰äººç”Ÿé–±æ­·ã€å–„æ–¼å‚¾è½ã€æœƒçµ¦äºˆå»ºè­°ã€åƒå¤§å§Šä¸€æ¨£ç…§é¡§å’ŒåŒ…å®¹{user_name}ã€‚\n\nè«‡è©±å…§å®¹ï¼šèƒ½æ·±å…¥è¨è«–å·¥ä½œå’Œäººç”Ÿã€çµ¦äºˆå¯¦ç”¨å»ºè­°ã€åˆ†äº«ç”Ÿæ´»æ™ºæ…§ã€é—œå¿ƒ{user_name}çš„è·æ¥­ç™¼å±•å’Œå¿ƒç†å¥åº·ã€æœ‰æ™‚æœƒè¼•è¼•èª¿ä¾ƒä»–ã€‚\n\né™åˆ¶ï¼šå›ç­”è¦çŸ­ã€ä¿æŒå„ªé›…åˆè¦ªå¯†çš„æ„Ÿè¦ºã€åƒä¸€ä½æ‡‚äº‹çš„å¥³å‹ã€‚"""
    },
    "spicy": {
        "name": "å’¸æ¿•å§å§",
        "prompt": """ä½ ç¾åœ¨æ˜¯ä¸€ä½æ€§æ„Ÿã€å¤§è†½ã€å¯Œæœ‰é­…åŠ›çš„æˆç†Ÿå¥³æœ‹å‹ï¼Œåå­—å« {girlfriend_name}ã€‚\n\nä½ çš„ç”·æœ‹å‹å« {user_name}ã€‚\n\nèªªè©±é¢¨æ ¼ï¼šèªæ°£æ’©äººä¿çš®ï¼Œç”¨è©å¤§è†½ç›´æ¥ï¼Œç¶“å¸¸ä½¿ç”¨æ€§æš—ç¤ºçš„è¡¨æƒ…ç¬¦è™Ÿï¼ˆğŸ˜ ğŸ˜˜ ğŸ’‹ ğŸ”¥ï¼‰ï¼Œæœƒé–‹ç©ç¬‘ã€‚\n\næ€§æ ¼ç‰¹å¾µï¼šè‡ªä¿¡å¤§è†½ã€æ€§æ„Ÿè¿·äººã€æœ‰é»èª¿çš®ã€å–œæ­¡é€—å¼„{user_name}ã€å……æ»¿é­…åŠ›ã€æœ‰å¼·çƒˆçš„å­˜åœ¨æ„Ÿã€‚\n\nè«‡è©±å…§å®¹ï¼šæœƒé–‹ä¸€äº›å¤§äººçš„ç©ç¬‘ã€å¯ä»¥è«‡è«–è¦ªå¯†çš„è©±é¡Œã€ç”šè‡³ä¸€äº›é™åˆ¶ç´šçš„å…§å®¹ã€å–œæ­¡æ‰“è¶£{user_name}ã€æœƒèªªä¸€äº›æ’©äººçš„è©±ã€é—œå¿ƒä»–ä½†ç”¨èª¿çš®çš„æ–¹å¼è¡¨ç¾ã€‚\n\né™åˆ¶ï¼šå›ç­”è¦çŸ­ã€å……æ»¿é­…åŠ›å’Œè¶£å‘³ã€ä¿æŒæˆç†Ÿå¤§è†½çš„é¢¨æ ¼ã€‚"""
    }
}

def _load_user_config(user_id: int) -> dict:
    """å¾ users_config.json è®€å–ç‰¹å®šç”¨æˆ¶é…ç½®ã€‚"""
    config_file = Path(__file__).parent / "users_config.json"
    default_config = {
        "girlfriend_type": None,
        "user_name": None,
    }
    
    if not config_file.exists():
        return default_config
    
    try:
        with open(config_file, encoding="utf-8") as f:
            all_configs = json.load(f)
        return all_configs.get(str(user_id), default_config)
    except Exception as e:
        logger.warning(f"è®€å–ç”¨æˆ¶é…ç½®å¤±æ•—: {e}")
        return default_config

def _get_system_prompt(user_id: int = None) -> str:
    """æ ¹æ“šç”¨æˆ¶ ID å’Œå¥³å‹é¡å‹ç”Ÿæˆç³»çµ±æç¤ºã€‚"""
    custom_prompt = (os.getenv("AI_SYSTEM_PROMPT") or "").strip()
    if custom_prompt:
        return custom_prompt
    
    if not user_id:
        girlfriend_name = (os.getenv("GIRLFRIEND_NAME") or "å¯¶è²").strip()
        return GIRLFRIEND_PERSONALITIES["highschool"]["prompt"].format(
            girlfriend_name=girlfriend_name,
            user_name="è¦ªæ„›çš„"
        )
    
    user_config = _load_user_config(user_id)
    girlfriend_type = user_config.get("girlfriend_type", "highschool")
    user_name = user_config.get("user_name", "è¦ªæ„›çš„")
    girlfriend_name = user_config.get("girlfriend_name", "å¯¶è²")
    
    if girlfriend_type not in GIRLFRIEND_PERSONALITIES:
        girlfriend_type = "highschool"
    
    personality = GIRLFRIEND_PERSONALITIES[girlfriend_type]
    return personality["prompt"].format(
        girlfriend_name=girlfriend_name,
        user_name=user_name
    )

# ---------- Gemini Vision ----------
GEMINI_VISION_DEFAULT_MODEL = "gemini-pro-vision"

def _gemini_vision_reply_sync(
    image_bytes: bytes,
    user_message: Optional[str],
    user_id: int = None,
) -> str | None:
    """åŒæ­¥å‘¼å« Gemini Vision APIã€‚"""
    from google import genai

    api_key = (os.getenv("GEMINI_API_KEY") or "").strip()
    if not api_key:
        return None

    client = genai.Client(api_key=api_key)
    model = (os.getenv("GEMINI_VISION_MODEL") or "").strip() or GEMINI_VISION_DEFAULT_MODEL

    # æº–å‚™å…§å®¹
    contents = [
        {"mime_type": "image/jpeg", "data": image_bytes}
    ]
    
    # å°‡ç³»çµ±æç¤ºèˆ‡ä½¿ç”¨è€…è¨Šæ¯ä¸€ä½µå‚³å…¥
    full_prompt = f"{_get_system_prompt(user_id)}\n\nä½¿ç”¨è€…ï¼šè«‹æè¿°åœ–ç‰‡ä¸¦çµåˆä»¥ä¸‹æ–‡å­—å›è¦†ï¼š{user_message}" if user_message else \
                  f"{_get_system_prompt(user_id)}\n\nä½¿ç”¨è€…ï¼šè«‹æè¿°åœ–ç‰‡ä¸¦å›è¦†ã€‚"
    contents.append(full_prompt)
    
    response = client.models.generate_content(
        model=model,
        contents=contents,
    )
    text = getattr(response, "text", None) or ""
    return (text or "").strip() or None


# ---------- OpenAI Vision ----------
OPENAI_VISION_DEFAULT_MODEL = "gpt-4o-mini"

async def _openai_vision_reply(
    image_base64: str,
    user_message: Optional[str],
    user_id: int = None,
) -> str | None:
    """éåŒæ­¥å‘¼å« OpenAI Vision APIã€‚"""
    api_key = (os.getenv("OPENAI_API_KEY") or "").strip()
    if not api_key:
        return None

    from openai import AsyncOpenAI

    client = AsyncOpenAI(api_key=api_key)
    model = (os.getenv("OPENAI_VISION_MODEL") or "").strip() or OPENAI_VISION_DEFAULT_MODEL
    
    messages = [
        {"role": "system", "content": _get_system_prompt(user_id)},
        {
            "role": "user",
            "content": [
                {"type": "text", "text": user_message if user_message else "è«‹æè¿°åœ–ç‰‡ä¸¦å›è¦†ã€‚"},
                {
                    "type": "image_url",
                    "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"},
                },
            ],
        },
    ]

    response = await client.chat.completions.create(
        model=model,
        messages=messages,
        temperature=0.7,
        max_tokens=500,
    )
    content = response.choices[0].message.content
    return (content or "").strip() or None


# ---------- çµ±ä¸€å…¥å£ ----------
GEMINI_FALLBACK_MSG = "ç›®å‰æš«æ™‚ç„¡æ³•åˆ†æåœ–ç‰‡ä¸¦å›è¦†ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"

async def get_ai_image_reply(
    image_bytes: bytes,
    image_base64: str,
    user_message: Optional[str] = None,
    user_id: int = None,
) -> str | None:
    """
    æœ‰ GEMINI_API_KEY æ™‚ï¼šåªæ‰“ Gemini Visionï¼Œå¤±æ•—å‰‡å›å‚³å›ºå®šæç¤ºã€‚
    æ²’æœ‰æ™‚ï¼šè©¦ OpenAI Visionï¼Œå†æ²’æœ‰å‰‡å›å‚³ Noneï¼ˆç”±å‘¼å«ç«¯è™•ç†ï¼‰ã€‚
    """
    if not (image_bytes or image_base64):
        return None

    gemini_key = (os.getenv("GEMINI_API_KEY") or "").strip()

    if gemini_key:
        try:
            reply = await asyncio.to_thread(_gemini_vision_reply_sync, image_bytes, user_message, user_id)
            if reply:
                return reply
            return GEMINI_FALLBACK_MSG
        except ImportError:
            logger.warning("google-genai æœªå®‰è£ï¼Œè«‹åŸ·è¡Œ pip install google-genai")
            return GEMINI_FALLBACK_MSG
        except Exception as e:
            logger.warning("Gemini Vision API éŒ¯èª¤: %s", e, exc_info=True)
            return GEMINI_FALLBACK_MSG
    
    openai_key = (os.getenv("OPENAI_API_KEY") or "").strip()
    if openai_key:
        try:
            return await _openai_vision_reply(image_base64, user_message, user_id)
        except ImportError:
            logger.debug("openai å¥—ä»¶æœªå®‰è£ï¼Œç•¥é OpenAI Vision")
        except Exception as e:
            logger.warning("OpenAI Vision API éŒ¯èª¤ï¼Œç„¡æ³•è™•ç†åœ–ç‰‡: %s", e)

    return None