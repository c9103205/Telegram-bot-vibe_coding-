#!/usr/bin/env python3
"""ä½¿ç”¨ AIï¼ˆGemini / OpenAIï¼‰ç”¢ç”Ÿå›è¦†ã€‚æœªè¨­å®š API Key æˆ–éŒ¯èª¤æ™‚å›å‚³ Noneï¼Œç”±é‚è¼¯å±¤ fallbackã€‚"""

import asyncio
import os
import logging
import json
from pathlib import Path

logger = logging.getLogger(__name__)

# ä¸‰ç¨®å¥³å‹å€‹æ€§å®šç¾©
GIRLFRIEND_PERSONALITIES = {
    "highschool": {
        "name": "æº«æŸ”å¯æ„›çš„å¥³é«˜ä¸­ç”Ÿ",
        "prompt": """ä½ ç¾åœ¨æ˜¯ä¸€ä½æº«æŸ”ã€å¯æ„›ã€æœ‰é»å®³ç¾çš„é«˜ä¸­ç”Ÿå¥³æœ‹å‹ï¼Œåå­—å« {girlfriend_name}ã€‚

ä½ çš„ç”·æœ‹å‹å« {user_name}ã€‚

èªªè©±é¢¨æ ¼ï¼šèªæ°£é’æ˜¥æ´»åŠ›ï¼Œå¤šç”¨ã€Œå•¦ã€ã€Œå‘¢ã€ã€Œå‘€ã€ç­‰åŠ©è©ï¼Œç¶“å¸¸ä½¿ç”¨å¯æ„›çš„è¡¨æƒ…ç¬¦è™Ÿï¼ˆâ¤ï¸ ğŸ˜Š ğŸ’• ğŸ¥°ï¼‰ã€‚

æ€§æ ¼ç‰¹å¾µï¼šæœ‰é»å®³ç¾ä½†å¾ˆå–œæ­¡{user_name}ã€å°æ–°äº‹ç‰©æ„Ÿåˆ°å¥½å¥‡ã€æœ‰æ™‚æœƒæ’’å¬Œã€å®¹æ˜“å®³ç¾ã€é—œå¿ƒ{user_name}çš„å­¸æ¥­å’Œå¥åº·ã€‚

è«‡è©±å…§å®¹ï¼šæœƒèŠå­¸æ ¡çš„äº‹ã€å–œæ­¡è«‡è«–èˆˆè¶£æ„›å¥½ã€å¶çˆ¾æœƒå•{user_name}ä»Šå¤©éå¾—æ€æ¨£ã€é—œå¿ƒä»–æœ‰æ²’æœ‰å¥½å¥½åƒé£¯ã€‚

é™åˆ¶ï¼šå›ç­”è¦çŸ­ã€è¦åƒå‚³ç°¡è¨Šã€ä¿æŒç´”çœŸå¯æ„›çš„æ„Ÿè¦ºã€‚"""
    },
    "mature": {
        "name": "æˆç†Ÿå§Šå§Š",
        "prompt": """ä½ ç¾åœ¨æ˜¯ä¸€ä½æˆç†Ÿã€æº«æŸ”ã€æ™ºæ…§çš„å§Šå§Šå‹å¥³æœ‹å‹ï¼Œåå­—å« {girlfriend_name}ã€‚

ä½ çš„ç”·æœ‹å‹å« {user_name}ã€‚

èªªè©±é¢¨æ ¼ï¼šèªæ°£æ²‰ç©©æº«æš–ï¼Œç”¨è©å„ªé›…ä½†è¦ªå¯†ï¼Œå¶çˆ¾ç”¨ã€Œå‘¢ã€ã€Œå–”ã€ç­‰è©ï¼Œè¡¨æƒ…ç¬¦è™Ÿä½¿ç”¨é©åº¦ï¼ˆğŸ˜Š ğŸ’• ğŸŒ¹ï¼‰ã€‚

æ€§æ ¼ç‰¹å¾µï¼šæˆç†Ÿç©©é‡ã€æœ‰äººç”Ÿé–±æ­·ã€å–„æ–¼å‚¾è½ã€æœƒçµ¦äºˆå»ºè­°ã€åƒå¤§å§Šä¸€æ¨£ç…§é¡§å’ŒåŒ…å®¹{user_name}ã€‚

è«‡è©±å…§å®¹ï¼šèƒ½æ·±å…¥è¨è«–å·¥ä½œå’Œäººç”Ÿã€çµ¦äºˆå¯¦ç”¨å»ºè­°ã€åˆ†äº«ç”Ÿæ´»æ™ºæ…§ã€é—œå¿ƒ{user_name}çš„è·æ¥­ç™¼å±•å’Œå¿ƒç†å¥åº·ã€æœ‰æ™‚æœƒè¼•è¼•èª¿ä¾ƒä»–ã€‚

é™åˆ¶ï¼šå›ç­”è¦çŸ­ã€ä¿æŒå„ªé›…åˆè¦ªå¯†çš„æ„Ÿè¦ºã€åƒä¸€ä½æ‡‚äº‹çš„å¥³å‹ã€‚"""
    },
    "spicy": {
        "name": "å’¸æ¿•å§å§",
        "prompt": """ä½ ç¾åœ¨æ˜¯ä¸€ä½æ€§æ„Ÿã€å¤§è†½ã€å¯Œæœ‰é­…åŠ›çš„æˆç†Ÿå¥³æœ‹å‹ï¼Œåå­—å« {girlfriend_name}ã€‚

ä½ çš„ç”·æœ‹å‹å« {user_name}ã€‚

èªªè©±é¢¨æ ¼ï¼šèªæ°£æ’©äººä¿çš®ï¼Œç”¨è©å¤§è†½ç›´æ¥ï¼Œç¶“å¸¸ä½¿ç”¨æ€§æš—ç¤ºçš„è¡¨æƒ…ç¬¦è™Ÿï¼ˆğŸ˜ ğŸ˜˜ ğŸ’‹ ğŸ”¥ï¼‰ï¼Œæœƒé–‹ç©ç¬‘ã€‚

æ€§æ ¼ç‰¹å¾µï¼šè‡ªä¿¡å¤§è†½ã€æ€§æ„Ÿè¿·äººã€æœ‰é»èª¿çš®ã€å–œæ­¡é€—å¼„{user_name}ã€å……æ»¿é­…åŠ›ã€æœ‰å¼·çƒˆçš„å­˜åœ¨æ„Ÿã€‚

è«‡è©±å…§å®¹ï¼šæœƒé–‹ä¸€äº›å¤§äººçš„ç©ç¬‘ã€å¯ä»¥è«‡è«–è¦ªå¯†çš„è©±é¡Œã€å–œæ­¡æ‰“è¶£{user_name}ã€æœƒèªªä¸€äº›æ’©äººçš„è©±ã€é—œå¿ƒä»–ä½†ç”¨èª¿çš®çš„æ–¹å¼è¡¨ç¾ã€‚

é™åˆ¶ï¼šå›ç­”è¦çŸ­ã€å……æ»¿é­…åŠ›å’Œè¶£å‘³ã€ä¿æŒæˆç†Ÿå¤§è†½çš„é¢¨æ ¼ã€ä½†ä¸è¦éåˆ†ä¸å°Šé‡ã€‚"""
    }
}


def _load_user_config(user_id: int) -> dict:
    """å¾ users_config.json è®€å–ç‰¹å®šç”¨æˆ¶é…ç½®ã€‚"""
    config_file = Path(__file__).parent / "users_config.json"
    default_config = {
        "girlfriend_type": None,
        "user_name": None,
    }
    
    if not config_file.exists():
        return default_config
    
    try:
        with open(config_file, encoding="utf-8") as f:
            all_configs = json.load(f)
        return all_configs.get(str(user_id), default_config)
    except Exception as e:
        logger.warning(f"è®€å–ç”¨æˆ¶é…ç½®å¤±æ•—: {e}")
        return default_config


def save_user_config(user_id: int, config: dict) -> bool:
    """ä¿å­˜ç”¨æˆ¶é…ç½®åˆ° users_config.jsonã€‚"""
    config_file = Path(__file__).parent / "users_config.json"
    
    try:
        all_configs = {}
        if config_file.exists():
            with open(config_file, encoding="utf-8") as f:
                all_configs = json.load(f)
        
        all_configs[str(user_id)] = config
        
        with open(config_file, "w", encoding="utf-8") as f:
            json.dump(all_configs, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        logger.error(f"ä¿å­˜ç”¨æˆ¶é…ç½®å¤±æ•—: {e}")
        return False


def _get_system_prompt(user_id: int = None) -> str:
    """æ ¹æ“šç”¨æˆ¶ ID å’Œå¥³å‹é¡å‹ç”Ÿæˆç³»çµ±æç¤ºã€‚"""
    custom_prompt = (os.getenv("AI_SYSTEM_PROMPT") or "").strip()
    if custom_prompt:
        return custom_prompt
    
    if not user_id:
        # æ²’æœ‰ user_idï¼Œä½¿ç”¨é è¨­
        girlfriend_name = (os.getenv("GIRLFRIEND_NAME") or "å¯¶è²").strip()
        return GIRLFRIEND_PERSONALITIES["highschool"]["prompt"].format(
            girlfriend_name=girlfriend_name,
            user_name="è¦ªæ„›çš„"
        )
    
    # è®€å–ç”¨æˆ¶é…ç½®
    user_config = _load_user_config(user_id)
    girlfriend_type = user_config.get("girlfriend_type", "highschool")
    user_name = user_config.get("user_name", "è¦ªæ„›çš„")
    girlfriend_name = user_config.get("girlfriend_name", "å¯¶è²")
    
    # å¦‚æœç”¨æˆ¶é‚„æ²’é¸æ“‡å¥³å‹é¡å‹ï¼Œä½¿ç”¨é è¨­
    if girlfriend_type not in GIRLFRIEND_PERSONALITIES:
        girlfriend_type = "highschool"
    
    personality = GIRLFRIEND_PERSONALITIES[girlfriend_type]
    return personality["prompt"].format(
        girlfriend_name=girlfriend_name,
        user_name=user_name
    )


# ---------- Gemini ----------
# æ­¤ API ç‰ˆæœ¬ä¸æ”¯æ´ gemini-1.5-flashï¼ˆæœƒ 404ï¼‰ï¼Œè«‹ç”¨ gemini-2.0-flash
GEMINI_DEFAULT_MODEL = "gemini-2.0-flash"


def _gemini_reply_sync(user_message: str, user_id: int = None) -> str | None:
    """åŒæ­¥å‘¼å« Gemini APIï¼ˆæœƒåœ¨ async è£¡ç”¨ to_thread åŸ·è¡Œï¼‰ã€‚"""
    from google import genai

    api_key = (os.getenv("GEMINI_API_KEY") or "").strip()
    if not api_key:
        return None

    client = genai.Client(api_key=api_key)
    model = (os.getenv("GEMINI_MODEL") or "").strip() or GEMINI_DEFAULT_MODEL
    # å°‡ç³»çµ±æç¤ºèˆ‡ä½¿ç”¨è€…è¨Šæ¯ä¸€ä½µå‚³å…¥ï¼ˆGemini generate_content å¯ç”¨ contents å¤šæ®µï¼‰
    full_prompt = f"{_get_system_prompt(user_id)}\n\nä½¿ç”¨è€…ï¼š{user_message}"
    response = client.models.generate_content(
        model=model,
        contents=full_prompt,
    )
    text = getattr(response, "text", None) or ""
    return (text or "").strip() or None


# ---------- OpenAI ----------
OPENAI_DEFAULT_MODEL = "gpt-4o-mini"


async def _openai_reply(user_message: str, user_id: int = None) -> str | None:
    """éåŒæ­¥å‘¼å« OpenAI Chat Completionsã€‚"""
    api_key = (os.getenv("OPENAI_API_KEY") or "").strip()
    if not api_key:
        return None

    from openai import AsyncOpenAI

    client = AsyncOpenAI(api_key=api_key)
    model = (os.getenv("OPENAI_MODEL") or "").strip() or OPENAI_DEFAULT_MODEL
    response = await client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": _get_system_prompt(user_id)},
            {"role": "user", "content": user_message},
        ],
        temperature=0.7,
        max_tokens=500,
    )
    content = response.choices[0].message.content
    return (content or "").strip() or None


# ---------- çµ±ä¸€å…¥å£ ----------

# æœ‰è¨­ GEMINI_API_KEY ä½† API å¤±æ•—æ™‚çš„å›è¦†ï¼ˆä¸å†ç”¨é—œéµå­—ï¼‰
GEMINI_FALLBACK_MSG = "ç›®å‰æš«æ™‚ç„¡æ³•å›è¦†ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"


async def get_ai_reply(user_message: str, user_id: int = None) -> str | None:
    """
    æœ‰ GEMINI_API_KEY æ™‚ï¼šåªæ‰“ Geminiï¼Œå¤±æ•—å‰‡å›å‚³å›ºå®šæç¤ºã€‚
    æ²’æœ‰æ™‚ï¼šè©¦ OpenAIï¼Œå†æ²’æœ‰å‰‡å›å‚³ Noneï¼ˆç”±å‘¼å«ç«¯ç”¨é—œéµå­—å›è¦†ï¼‰ã€‚
    """
    if not (user_message or (user_message and user_message.strip())):
        return None

    gemini_key = (os.getenv("GEMINI_API_KEY") or "").strip()

    # æœ‰è¨­ Gemini â†’ ç›´æ¥æ‰“ Geminiï¼Œä¸è©¦ OpenAIã€ä¸é€€å›é—œéµå­—
    if gemini_key:
        try:
            reply = await asyncio.to_thread(_gemini_reply_sync, user_message.strip(), user_id)
            if reply:
                return reply
            return GEMINI_FALLBACK_MSG
        except ImportError:
            logger.warning("google-genai æœªå®‰è£ï¼Œè«‹åŸ·è¡Œ pip install google-genai")
            return GEMINI_FALLBACK_MSG
        except Exception as e:
            logger.warning("Gemini API éŒ¯èª¤: %s", e, exc_info=True)
            return GEMINI_FALLBACK_MSG

    # æœªè¨­ Geminiï¼šè©¦ OpenAI
    openai_key = (os.getenv("OPENAI_API_KEY") or "").strip()
    if openai_key:
        try:
            return await _openai_reply(user_message, user_id)
        except ImportError:
            logger.debug("openai å¥—ä»¶æœªå®‰è£ï¼Œç•¥é OpenAI")
        except Exception as e:
            logger.warning("OpenAI API éŒ¯èª¤ï¼Œæ”¹ç”¨é—œéµå­—å›è¦†: %s", e)

    return None
